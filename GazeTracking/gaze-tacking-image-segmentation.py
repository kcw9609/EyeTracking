import cv2
from ultralytics import YOLO
from gaze_tracking import GazeTracking

# YOLO Segmentation ëª¨ë¸ ë¡œë“œ
model = YOLO("yolov8n-seg.pt")  # yolov8s-seg.pt, yolov8m-seg.pt ë“±ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥

# ì‹œì„  ì¶”ì ê¸° ì´ˆê¸°í™”
gaze = GazeTracking()

# ì´ë¯¸ì§€ ë¡œë“œ ë° ë¦¬ì‚¬ì´ì¦ˆ
image_path = "./test-images/image-1.jpeg"
img = cv2.imread(image_path)
screen_width, screen_height = 1280, 720
img = cv2.resize(img, (screen_width, screen_height))

# YOLO ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
results = model(img, conf=0.3)[0]  # ì²« ë²ˆì§¸ ê²°ê³¼ë§Œ ì‚¬ìš©

# í´ë˜ìŠ¤ ë° ë§ˆìŠ¤í¬ ì •ë³´ ì¶”ì¶œ
class_names = model.names
masks = results.masks.data.cpu()  # (N, H, W)
boxes = results.boxes.xyxy.cpu().numpy()
classes = results.boxes.cls.cpu().numpy().astype(int)

# ì‹œê°í™”ìš© ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„±
annotated_img = results.plot()

# ê°ì²´ ë§ˆìŠ¤í¬ì™€ í´ë˜ìŠ¤ëª… ì €ì¥
object_masks = []
for i in range(len(masks)):
    mask = masks[i]
    class_id = classes[i]
    label = class_names[class_id]
    object_masks.append((mask, label))

# ì›¹ìº ìœ¼ë¡œ ì‹œì„  ì¶”ì 
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1)  # ì…€ì¹´ì²˜ëŸ¼ ë°˜ì „
    gaze.refresh(frame)

    gaze_x = gaze.horizontal_ratio()
    gaze_y = gaze.vertical_ratio()

    result = annotated_img.copy()  # ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬
    text = ""

    if gaze_x is not None and gaze_y is not None:
        # ì‹œì„  ìœ„ì¹˜ (ì´ë¯¸ì§€ ê¸°ì¤€ ì¢Œí‘œ)
        screen_x = int(gaze_x * screen_width)
        screen_y = int(gaze_y * screen_height)

        # í‘œì‹œìš© ë™ê·¸ë¼ë¯¸
        cv2.circle(result, (screen_x, screen_y), 8, (0, 0, 255), -1)

        found_obj = None
        for mask, label in object_masks:
            h_mask, w_mask = mask.shape

            # ë§ˆìŠ¤í¬ ì¢Œí‘œ ê¸°ì¤€ ì‹œì„  ìœ„ì¹˜ ê³„ì‚°
            mask_x = int(gaze_x * w_mask)
            mask_y = int(gaze_y * h_mask)

            # ìœ íš¨ ì¢Œí‘œì¸ì§€ í™•ì¸ í›„ ê²€ì‚¬
            if 0 <= mask_x < w_mask and 0 <= mask_y < h_mask:
                if mask[mask_y, mask_x] > 0.5:
                    found_obj = label
                    break

        if found_obj:
            text = f"ğŸ‘ï¸ ë°”ë¼ë³´ëŠ” ê°ì²´: {found_obj}"
        else:
            text = "ğŸ‘ï¸ ê°ì²´ ì˜ì—­ì´ ì•„ë‹˜"
    else:
        text = "ğŸ˜´ ëˆˆ ê°ì•˜ê±°ë‚˜ ì¸ì‹ ë¶ˆê°€"

    # ê²°ê³¼ ì¶œë ¥
    cv2.putText(result, text, (50, 60), cv2.FONT_HERSHEY_DUPLEX, 1.2, (0, 0, 255), 3)
    cv2.imshow("Segmentation + Gaze Tracking", result)

    if cv2.waitKey(1) == 27:  # ESC ëˆ„ë¥´ë©´ ì¢…ë£Œ
        break

cap.release()
cv2.destroyAllWindows()
